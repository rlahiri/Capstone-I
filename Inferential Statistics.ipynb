{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target Variable(s): Executive Function Scores**\n",
    "\n",
    "1. Interference\n",
    "2. Working Memory\n",
    "3. Cognitive Flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import + Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.ExcelFile('/Users/springboard/Desktop/Springboard-Coursework/Obesity.xlsx')\n",
    "\n",
    "df = data.parse('Full sample_EF_excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 513 entries, 0 to 512\n",
      "Data columns (total 25 columns):\n",
      "Reference_no              513 non-null int64\n",
      "Actual_age_C              513 non-null float64\n",
      "Sex                       513 non-null int64\n",
      "Weight                    513 non-null float64\n",
      "Height_meter              513 non-null float64\n",
      "BMI                       513 non-null float64\n",
      "BMI_for_age               513 non-null float64\n",
      "Physical_fitness_score    513 non-null float64\n",
      "PFS_CAT                   513 non-null int64\n",
      "Breakfast                 513 non-null int64\n",
      "Lunch                     513 non-null int64\n",
      "Dinner                    513 non-null int64\n",
      "PA_total_score            513 non-null float64\n",
      "PA_CAT                    513 non-null int64\n",
      "Sleep_weekdays            513 non-null float64\n",
      "Sleep_weekend             513 non-null float64\n",
      "Sleep_percent             513 non-null float64\n",
      "Global_sleep_CAT          513 non-null int64\n",
      "Household_size            486 non-null float64\n",
      "Income_CAT                486 non-null float64\n",
      "Edu_father                486 non-null float64\n",
      "Edu_mother                486 non-null float64\n",
      "Interference_score_ALL    513 non-null float64\n",
      "WM_total                  513 non-null int64\n",
      "CF_total                  513 non-null float64\n",
      "dtypes: float64(16), int64(9)\n",
      "memory usage: 100.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference_no</th>\n",
       "      <th>Actual_age_C</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height_meter</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BMI_for_age</th>\n",
       "      <th>Physical_fitness_score</th>\n",
       "      <th>PFS_CAT</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>...</th>\n",
       "      <th>Sleep_weekend</th>\n",
       "      <th>Sleep_percent</th>\n",
       "      <th>Global_sleep_CAT</th>\n",
       "      <th>Household_size</th>\n",
       "      <th>Income_CAT</th>\n",
       "      <th>Edu_father</th>\n",
       "      <th>Edu_mother</th>\n",
       "      <th>Interference_score_ALL</th>\n",
       "      <th>WM_total</th>\n",
       "      <th>CF_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.106776</td>\n",
       "      <td>2</td>\n",
       "      <td>30.6</td>\n",
       "      <td>1.420</td>\n",
       "      <td>15.175560</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7.25</td>\n",
       "      <td>95.238095</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.409091</td>\n",
       "      <td>16</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.114990</td>\n",
       "      <td>1</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1.492</td>\n",
       "      <td>15.004061</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.50</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.697183</td>\n",
       "      <td>16</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12.125941</td>\n",
       "      <td>1</td>\n",
       "      <td>66.8</td>\n",
       "      <td>1.518</td>\n",
       "      <td>28.988979</td>\n",
       "      <td>2.86</td>\n",
       "      <td>55.045872</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>91.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.598361</td>\n",
       "      <td>16</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12.139630</td>\n",
       "      <td>1</td>\n",
       "      <td>40.4</td>\n",
       "      <td>1.466</td>\n",
       "      <td>18.798077</td>\n",
       "      <td>0.53</td>\n",
       "      <td>56.206089</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.00</td>\n",
       "      <td>76.190476</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>15</td>\n",
       "      <td>45.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12.167009</td>\n",
       "      <td>2</td>\n",
       "      <td>40.1</td>\n",
       "      <td>1.475</td>\n",
       "      <td>18.431485</td>\n",
       "      <td>0.12</td>\n",
       "      <td>63.829787</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.25</td>\n",
       "      <td>98.876404</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.291339</td>\n",
       "      <td>15</td>\n",
       "      <td>15.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reference_no  Actual_age_C  Sex  Weight  Height_meter        BMI  \\\n",
       "0             1     12.106776    2    30.6         1.420  15.175560   \n",
       "1             2     12.114990    1    33.4         1.492  15.004061   \n",
       "2             3     12.125941    1    66.8         1.518  28.988979   \n",
       "3             4     12.139630    1    40.4         1.466  18.798077   \n",
       "4             5     12.167009    2    40.1         1.475  18.431485   \n",
       "\n",
       "   BMI_for_age  Physical_fitness_score  PFS_CAT  Breakfast  ...  \\\n",
       "0        -1.51               54.545455        1          7  ...   \n",
       "1        -1.60               62.500000        2          7  ...   \n",
       "2         2.86               55.045872        2          6  ...   \n",
       "3         0.53               56.206089        2          7  ...   \n",
       "4         0.12               63.829787        2          7  ...   \n",
       "\n",
       "   Sleep_weekend  Sleep_percent  Global_sleep_CAT  Household_size  Income_CAT  \\\n",
       "0           7.25      95.238095                 1             6.0         2.0   \n",
       "1          11.50      95.652174                 0             4.0         3.0   \n",
       "2           8.00      91.428571                 1             3.0         1.0   \n",
       "3          11.00      76.190476                 1             4.0         1.0   \n",
       "4          11.25      98.876404                 0             3.0         1.0   \n",
       "\n",
       "   Edu_father  Edu_mother  Interference_score_ALL  WM_total  CF_total  \n",
       "0         3.0         3.0               10.409091        16     18.00  \n",
       "1         4.0         3.0               -2.697183        16     27.00  \n",
       "2         3.0         2.0                6.598361        16      4.31  \n",
       "3         3.0         4.0                1.454545        15     45.16  \n",
       "4         2.0         3.0                0.291339        15     15.07  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference_no</th>\n",
       "      <th>Actual_age_C</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height_meter</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BMI_for_age</th>\n",
       "      <th>Physical_fitness_score</th>\n",
       "      <th>PFS_CAT</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>...</th>\n",
       "      <th>Sleep_weekend</th>\n",
       "      <th>Sleep_percent</th>\n",
       "      <th>Global_sleep_CAT</th>\n",
       "      <th>Household_size</th>\n",
       "      <th>Income_CAT</th>\n",
       "      <th>Edu_father</th>\n",
       "      <th>Edu_mother</th>\n",
       "      <th>Interference_score_ALL</th>\n",
       "      <th>WM_total</th>\n",
       "      <th>CF_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.106776</td>\n",
       "      <td>2</td>\n",
       "      <td>30.6</td>\n",
       "      <td>1.4200</td>\n",
       "      <td>15.175560</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7.25</td>\n",
       "      <td>95.238095</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.409091</td>\n",
       "      <td>16</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.114990</td>\n",
       "      <td>1</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>15.004061</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.50</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.697183</td>\n",
       "      <td>16</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12.125941</td>\n",
       "      <td>1</td>\n",
       "      <td>66.8</td>\n",
       "      <td>1.5180</td>\n",
       "      <td>28.988979</td>\n",
       "      <td>2.86</td>\n",
       "      <td>55.045872</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>91.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.598361</td>\n",
       "      <td>16</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12.139630</td>\n",
       "      <td>1</td>\n",
       "      <td>40.4</td>\n",
       "      <td>1.4660</td>\n",
       "      <td>18.798077</td>\n",
       "      <td>0.53</td>\n",
       "      <td>56.206089</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.00</td>\n",
       "      <td>76.190476</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>15</td>\n",
       "      <td>45.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12.167009</td>\n",
       "      <td>2</td>\n",
       "      <td>40.1</td>\n",
       "      <td>1.4750</td>\n",
       "      <td>18.431485</td>\n",
       "      <td>0.12</td>\n",
       "      <td>63.829787</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.25</td>\n",
       "      <td>98.876404</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.291339</td>\n",
       "      <td>15</td>\n",
       "      <td>15.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>12.180698</td>\n",
       "      <td>1</td>\n",
       "      <td>53.5</td>\n",
       "      <td>1.6600</td>\n",
       "      <td>19.415009</td>\n",
       "      <td>0.76</td>\n",
       "      <td>56.074766</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.657534</td>\n",
       "      <td>17</td>\n",
       "      <td>24.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>12.183436</td>\n",
       "      <td>1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.4650</td>\n",
       "      <td>14.630339</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>79.207921</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.50</td>\n",
       "      <td>95.238095</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.225806</td>\n",
       "      <td>26</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>12.197125</td>\n",
       "      <td>1</td>\n",
       "      <td>61.4</td>\n",
       "      <td>1.5640</td>\n",
       "      <td>25.101223</td>\n",
       "      <td>2.26</td>\n",
       "      <td>73.394495</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>13</td>\n",
       "      <td>33.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>12.213552</td>\n",
       "      <td>2</td>\n",
       "      <td>46.4</td>\n",
       "      <td>1.5300</td>\n",
       "      <td>19.821436</td>\n",
       "      <td>0.62</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>70.422535</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.417178</td>\n",
       "      <td>16</td>\n",
       "      <td>15.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>12.213552</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.3990</td>\n",
       "      <td>13.795211</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>58.394161</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.853659</td>\n",
       "      <td>17</td>\n",
       "      <td>36.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>12.238193</td>\n",
       "      <td>2</td>\n",
       "      <td>36.4</td>\n",
       "      <td>1.5055</td>\n",
       "      <td>16.059790</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>49.896050</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>94.117647</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.058824</td>\n",
       "      <td>21</td>\n",
       "      <td>44.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>12.240931</td>\n",
       "      <td>1</td>\n",
       "      <td>57.2</td>\n",
       "      <td>1.4670</td>\n",
       "      <td>26.578826</td>\n",
       "      <td>2.50</td>\n",
       "      <td>52.631579</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.752212</td>\n",
       "      <td>17</td>\n",
       "      <td>18.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>12.246407</td>\n",
       "      <td>1</td>\n",
       "      <td>44.6</td>\n",
       "      <td>1.4470</td>\n",
       "      <td>21.300892</td>\n",
       "      <td>1.36</td>\n",
       "      <td>52.516411</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.376812</td>\n",
       "      <td>19</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>12.265572</td>\n",
       "      <td>1</td>\n",
       "      <td>34.6</td>\n",
       "      <td>1.3930</td>\n",
       "      <td>17.830925</td>\n",
       "      <td>0.06</td>\n",
       "      <td>66.115702</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>97.297297</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>18</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>12.268309</td>\n",
       "      <td>1</td>\n",
       "      <td>27.8</td>\n",
       "      <td>1.3890</td>\n",
       "      <td>14.409214</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>75.675676</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.495868</td>\n",
       "      <td>15</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>12.268309</td>\n",
       "      <td>2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>1.4890</td>\n",
       "      <td>17.680587</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>75.471698</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.654412</td>\n",
       "      <td>19</td>\n",
       "      <td>14.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>12.276523</td>\n",
       "      <td>2</td>\n",
       "      <td>60.4</td>\n",
       "      <td>1.6050</td>\n",
       "      <td>23.446977</td>\n",
       "      <td>1.61</td>\n",
       "      <td>34.246575</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.25</td>\n",
       "      <td>91.139241</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.836735</td>\n",
       "      <td>12</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>12.290212</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6</td>\n",
       "      <td>1.4880</td>\n",
       "      <td>17.885016</td>\n",
       "      <td>0.08</td>\n",
       "      <td>76.190476</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>13.00</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>75.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>12.303901</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.5115</td>\n",
       "      <td>15.319752</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>54.669704</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9.50</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>16</td>\n",
       "      <td>30.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>12.306639</td>\n",
       "      <td>2</td>\n",
       "      <td>51.8</td>\n",
       "      <td>1.5655</td>\n",
       "      <td>21.136040</td>\n",
       "      <td>1.01</td>\n",
       "      <td>57.831325</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.219101</td>\n",
       "      <td>25</td>\n",
       "      <td>41.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>12.323066</td>\n",
       "      <td>1</td>\n",
       "      <td>58.2</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>26.144801</td>\n",
       "      <td>2.41</td>\n",
       "      <td>65.040650</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.189189</td>\n",
       "      <td>13</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>12.325804</td>\n",
       "      <td>1</td>\n",
       "      <td>54.4</td>\n",
       "      <td>1.5580</td>\n",
       "      <td>22.411142</td>\n",
       "      <td>1.64</td>\n",
       "      <td>79.734219</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7.50</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.343284</td>\n",
       "      <td>12</td>\n",
       "      <td>136.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>12.339493</td>\n",
       "      <td>1</td>\n",
       "      <td>49.6</td>\n",
       "      <td>1.4700</td>\n",
       "      <td>22.953399</td>\n",
       "      <td>1.77</td>\n",
       "      <td>56.872038</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>74.418605</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>15</td>\n",
       "      <td>58.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>12.350445</td>\n",
       "      <td>1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>1.4785</td>\n",
       "      <td>19.030521</td>\n",
       "      <td>0.55</td>\n",
       "      <td>76.433121</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>96.277279</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.560000</td>\n",
       "      <td>22</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>12.355921</td>\n",
       "      <td>1</td>\n",
       "      <td>41.8</td>\n",
       "      <td>1.3940</td>\n",
       "      <td>21.510511</td>\n",
       "      <td>1.39</td>\n",
       "      <td>65.040650</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>7.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.014388</td>\n",
       "      <td>18</td>\n",
       "      <td>53.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>12.369610</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.5095</td>\n",
       "      <td>22.821128</td>\n",
       "      <td>1.73</td>\n",
       "      <td>63.157895</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.376623</td>\n",
       "      <td>16</td>\n",
       "      <td>9.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>12.372348</td>\n",
       "      <td>2</td>\n",
       "      <td>45.6</td>\n",
       "      <td>1.4970</td>\n",
       "      <td>20.347977</td>\n",
       "      <td>0.75</td>\n",
       "      <td>59.113300</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.801527</td>\n",
       "      <td>14</td>\n",
       "      <td>47.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>12.388775</td>\n",
       "      <td>2</td>\n",
       "      <td>32.7</td>\n",
       "      <td>1.5250</td>\n",
       "      <td>14.060736</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>64.343164</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9.33</td>\n",
       "      <td>67.385445</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.617647</td>\n",
       "      <td>19</td>\n",
       "      <td>72.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>12.388775</td>\n",
       "      <td>2</td>\n",
       "      <td>50.3</td>\n",
       "      <td>1.4560</td>\n",
       "      <td>23.727131</td>\n",
       "      <td>1.65</td>\n",
       "      <td>58.679707</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>70.588235</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-8.172414</td>\n",
       "      <td>12</td>\n",
       "      <td>9.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>12.391513</td>\n",
       "      <td>1</td>\n",
       "      <td>56.4</td>\n",
       "      <td>1.5630</td>\n",
       "      <td>23.086662</td>\n",
       "      <td>1.79</td>\n",
       "      <td>59.259259</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.935484</td>\n",
       "      <td>17</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>484</td>\n",
       "      <td>16.019165</td>\n",
       "      <td>2</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1.5600</td>\n",
       "      <td>18.408941</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>60.453401</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.50</td>\n",
       "      <td>97.879282</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>16</td>\n",
       "      <td>13.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>485</td>\n",
       "      <td>16.024641</td>\n",
       "      <td>2</td>\n",
       "      <td>63.8</td>\n",
       "      <td>1.5490</td>\n",
       "      <td>26.589970</td>\n",
       "      <td>1.56</td>\n",
       "      <td>60.301508</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>98.176718</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.372414</td>\n",
       "      <td>15</td>\n",
       "      <td>41.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>486</td>\n",
       "      <td>16.030116</td>\n",
       "      <td>1</td>\n",
       "      <td>89.6</td>\n",
       "      <td>1.7540</td>\n",
       "      <td>29.123853</td>\n",
       "      <td>2.22</td>\n",
       "      <td>61.855670</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>97.297297</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.759036</td>\n",
       "      <td>22</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>487</td>\n",
       "      <td>16.035592</td>\n",
       "      <td>2</td>\n",
       "      <td>54.8</td>\n",
       "      <td>1.5690</td>\n",
       "      <td>22.260488</td>\n",
       "      <td>0.49</td>\n",
       "      <td>66.481994</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.975610</td>\n",
       "      <td>15</td>\n",
       "      <td>15.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>488</td>\n",
       "      <td>16.043806</td>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.6890</td>\n",
       "      <td>21.383094</td>\n",
       "      <td>0.32</td>\n",
       "      <td>80.267559</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.167630</td>\n",
       "      <td>18</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>489</td>\n",
       "      <td>16.052019</td>\n",
       "      <td>2</td>\n",
       "      <td>49.4</td>\n",
       "      <td>1.4720</td>\n",
       "      <td>22.798765</td>\n",
       "      <td>0.65</td>\n",
       "      <td>62.176166</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>88.421053</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.655914</td>\n",
       "      <td>17</td>\n",
       "      <td>41.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>490</td>\n",
       "      <td>16.057495</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.5205</td>\n",
       "      <td>25.952452</td>\n",
       "      <td>1.43</td>\n",
       "      <td>60.606061</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>12.50</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.942197</td>\n",
       "      <td>20</td>\n",
       "      <td>17.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>491</td>\n",
       "      <td>16.068446</td>\n",
       "      <td>2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>1.6940</td>\n",
       "      <td>21.884309</td>\n",
       "      <td>0.37</td>\n",
       "      <td>53.811659</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.653543</td>\n",
       "      <td>15</td>\n",
       "      <td>62.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>492</td>\n",
       "      <td>16.076660</td>\n",
       "      <td>2</td>\n",
       "      <td>66.2</td>\n",
       "      <td>1.5510</td>\n",
       "      <td>27.519111</td>\n",
       "      <td>1.74</td>\n",
       "      <td>57.553957</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>38.709677</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-11.116279</td>\n",
       "      <td>10</td>\n",
       "      <td>67.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>493</td>\n",
       "      <td>16.076660</td>\n",
       "      <td>2</td>\n",
       "      <td>46.2</td>\n",
       "      <td>1.6350</td>\n",
       "      <td>17.282496</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>70.588235</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8.50</td>\n",
       "      <td>94.193548</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.689655</td>\n",
       "      <td>20</td>\n",
       "      <td>14.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>494</td>\n",
       "      <td>16.076660</td>\n",
       "      <td>1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>1.6080</td>\n",
       "      <td>18.873295</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>77.419355</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.173611</td>\n",
       "      <td>19</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>495</td>\n",
       "      <td>16.079398</td>\n",
       "      <td>2</td>\n",
       "      <td>47.8</td>\n",
       "      <td>1.5130</td>\n",
       "      <td>20.880940</td>\n",
       "      <td>0.05</td>\n",
       "      <td>56.603774</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.25</td>\n",
       "      <td>101.818182</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.670886</td>\n",
       "      <td>20</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>16.087611</td>\n",
       "      <td>2</td>\n",
       "      <td>55.8</td>\n",
       "      <td>1.5270</td>\n",
       "      <td>23.930740</td>\n",
       "      <td>0.95</td>\n",
       "      <td>59.113300</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>16.093087</td>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.6040</td>\n",
       "      <td>26.430184</td>\n",
       "      <td>1.52</td>\n",
       "      <td>102.564103</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11.00</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.564103</td>\n",
       "      <td>16</td>\n",
       "      <td>19.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>16.095825</td>\n",
       "      <td>1</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1.6900</td>\n",
       "      <td>29.690837</td>\n",
       "      <td>2.30</td>\n",
       "      <td>65.934066</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.302326</td>\n",
       "      <td>18</td>\n",
       "      <td>56.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>16.106776</td>\n",
       "      <td>2</td>\n",
       "      <td>73.4</td>\n",
       "      <td>1.5830</td>\n",
       "      <td>29.291002</td>\n",
       "      <td>2.06</td>\n",
       "      <td>54.054054</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>80.898876</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.290323</td>\n",
       "      <td>15</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>16.131417</td>\n",
       "      <td>2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.5940</td>\n",
       "      <td>18.104277</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>28.846154</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.17</td>\n",
       "      <td>74.226804</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-19.459716</td>\n",
       "      <td>18</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>501</td>\n",
       "      <td>16.142368</td>\n",
       "      <td>1</td>\n",
       "      <td>51.6</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.854671</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>80.808081</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>51.612903</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.943396</td>\n",
       "      <td>11</td>\n",
       "      <td>37.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>502</td>\n",
       "      <td>16.243669</td>\n",
       "      <td>2</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.5650</td>\n",
       "      <td>30.295297</td>\n",
       "      <td>2.22</td>\n",
       "      <td>56.074766</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.00</td>\n",
       "      <td>95.948827</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.223077</td>\n",
       "      <td>15</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>503</td>\n",
       "      <td>16.284736</td>\n",
       "      <td>2</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1.5840</td>\n",
       "      <td>17.855321</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>64.171123</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>86.896552</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.878788</td>\n",
       "      <td>15</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>504</td>\n",
       "      <td>16.396988</td>\n",
       "      <td>1</td>\n",
       "      <td>56.8</td>\n",
       "      <td>1.6900</td>\n",
       "      <td>19.887259</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>66.298343</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.50</td>\n",
       "      <td>96.296296</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.228758</td>\n",
       "      <td>14</td>\n",
       "      <td>9.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>505</td>\n",
       "      <td>16.429843</td>\n",
       "      <td>1</td>\n",
       "      <td>60.2</td>\n",
       "      <td>1.6260</td>\n",
       "      <td>22.769600</td>\n",
       "      <td>0.92</td>\n",
       "      <td>62.176166</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.00</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>506</td>\n",
       "      <td>16.511978</td>\n",
       "      <td>2</td>\n",
       "      <td>88.3</td>\n",
       "      <td>1.6605</td>\n",
       "      <td>32.024543</td>\n",
       "      <td>2.46</td>\n",
       "      <td>65.573770</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>29</td>\n",
       "      <td>20.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>507</td>\n",
       "      <td>16.618754</td>\n",
       "      <td>2</td>\n",
       "      <td>49.7</td>\n",
       "      <td>1.5890</td>\n",
       "      <td>19.683784</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>61.381074</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10.50</td>\n",
       "      <td>85.287846</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.306667</td>\n",
       "      <td>20</td>\n",
       "      <td>22.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>508</td>\n",
       "      <td>16.624230</td>\n",
       "      <td>2</td>\n",
       "      <td>45.4</td>\n",
       "      <td>1.6140</td>\n",
       "      <td>17.428050</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>55.944056</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.214286</td>\n",
       "      <td>20</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>509</td>\n",
       "      <td>16.629706</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.6510</td>\n",
       "      <td>19.076961</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>78.431373</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>25</td>\n",
       "      <td>16.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>510</td>\n",
       "      <td>16.783025</td>\n",
       "      <td>1</td>\n",
       "      <td>57.4</td>\n",
       "      <td>1.7215</td>\n",
       "      <td>19.368583</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>59.850374</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11.00</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.154930</td>\n",
       "      <td>19</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>511</td>\n",
       "      <td>16.826831</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.6510</td>\n",
       "      <td>20.911284</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>77.669903</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>18</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>512</td>\n",
       "      <td>16.906229</td>\n",
       "      <td>2</td>\n",
       "      <td>53.2</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>23.644444</td>\n",
       "      <td>0.89</td>\n",
       "      <td>62.015504</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.469231</td>\n",
       "      <td>16</td>\n",
       "      <td>36.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>513</td>\n",
       "      <td>16.970000</td>\n",
       "      <td>2</td>\n",
       "      <td>40.2</td>\n",
       "      <td>1.7110</td>\n",
       "      <td>13.731755</td>\n",
       "      <td>-2.49</td>\n",
       "      <td>55.214724</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>7.50</td>\n",
       "      <td>87.209302</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.479532</td>\n",
       "      <td>17</td>\n",
       "      <td>15.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reference_no  Actual_age_C  Sex  Weight  Height_meter        BMI  \\\n",
       "0               1     12.106776    2    30.6        1.4200  15.175560   \n",
       "1               2     12.114990    1    33.4        1.4920  15.004061   \n",
       "2               3     12.125941    1    66.8        1.5180  28.988979   \n",
       "3               4     12.139630    1    40.4        1.4660  18.798077   \n",
       "4               5     12.167009    2    40.1        1.4750  18.431485   \n",
       "5               6     12.180698    1    53.5        1.6600  19.415009   \n",
       "6               7     12.183436    1    31.4        1.4650  14.630339   \n",
       "7               8     12.197125    1    61.4        1.5640  25.101223   \n",
       "8               9     12.213552    2    46.4        1.5300  19.821436   \n",
       "9              10     12.213552    2    27.0        1.3990  13.795211   \n",
       "10             11     12.238193    2    36.4        1.5055  16.059790   \n",
       "11             12     12.240931    1    57.2        1.4670  26.578826   \n",
       "12             13     12.246407    1    44.6        1.4470  21.300892   \n",
       "13             14     12.265572    1    34.6        1.3930  17.830925   \n",
       "14             15     12.268309    1    27.8        1.3890  14.409214   \n",
       "15             16     12.268309    2    39.2        1.4890  17.680587   \n",
       "16             17     12.276523    2    60.4        1.6050  23.446977   \n",
       "17             18     12.290212    1    39.6        1.4880  17.885016   \n",
       "18             19     12.303901    2    35.0        1.5115  15.319752   \n",
       "19             20     12.306639    2    51.8        1.5655  21.136040   \n",
       "20             21     12.323066    1    58.2        1.4920  26.144801   \n",
       "21             22     12.325804    1    54.4        1.5580  22.411142   \n",
       "22             23     12.339493    1    49.6        1.4700  22.953399   \n",
       "23             24     12.350445    1    41.6        1.4785  19.030521   \n",
       "24             25     12.355921    1    41.8        1.3940  21.510511   \n",
       "25             26     12.369610    1    52.0        1.5095  22.821128   \n",
       "26             27     12.372348    2    45.6        1.4970  20.347977   \n",
       "27             28     12.388775    2    32.7        1.5250  14.060736   \n",
       "28             29     12.388775    2    50.3        1.4560  23.727131   \n",
       "29             30     12.391513    1    56.4        1.5630  23.086662   \n",
       "..            ...           ...  ...     ...           ...        ...   \n",
       "483           484     16.019165    2    44.8        1.5600  18.408941   \n",
       "484           485     16.024641    2    63.8        1.5490  26.589970   \n",
       "485           486     16.030116    1    89.6        1.7540  29.123853   \n",
       "486           487     16.035592    2    54.8        1.5690  22.260488   \n",
       "487           488     16.043806    1    61.0        1.6890  21.383094   \n",
       "488           489     16.052019    2    49.4        1.4720  22.798765   \n",
       "489           490     16.057495    2    60.0        1.5205  25.952452   \n",
       "490           491     16.068446    2    62.8        1.6940  21.884309   \n",
       "491           492     16.076660    2    66.2        1.5510  27.519111   \n",
       "492           493     16.076660    2    46.2        1.6350  17.282496   \n",
       "493           494     16.076660    1    48.8        1.6080  18.873295   \n",
       "494           495     16.079398    2    47.8        1.5130  20.880940   \n",
       "495           496     16.087611    2    55.8        1.5270  23.930740   \n",
       "496           497     16.093087    2    68.0        1.6040  26.430184   \n",
       "497           498     16.095825    1    84.8        1.6900  29.690837   \n",
       "498           499     16.106776    2    73.4        1.5830  29.291002   \n",
       "499           500     16.131417    2    46.0        1.5940  18.104277   \n",
       "500           501     16.142368    1    51.6        1.7000  17.854671   \n",
       "501           502     16.243669    2    74.2        1.5650  30.295297   \n",
       "502           503     16.284736    2    44.8        1.5840  17.855321   \n",
       "503           504     16.396988    1    56.8        1.6900  19.887259   \n",
       "504           505     16.429843    1    60.2        1.6260  22.769600   \n",
       "505           506     16.511978    2    88.3        1.6605  32.024543   \n",
       "506           507     16.618754    2    49.7        1.5890  19.683784   \n",
       "507           508     16.624230    2    45.4        1.6140  17.428050   \n",
       "508           509     16.629706    1    52.0        1.6510  19.076961   \n",
       "509           510     16.783025    1    57.4        1.7215  19.368583   \n",
       "510           511     16.826831    1    57.0        1.6510  20.911284   \n",
       "511           512     16.906229    2    53.2        1.5000  23.644444   \n",
       "512           513     16.970000    2    40.2        1.7110  13.731755   \n",
       "\n",
       "     BMI_for_age  Physical_fitness_score  PFS_CAT  Breakfast  ...  \\\n",
       "0          -1.51               54.545455        1          7  ...   \n",
       "1          -1.60               62.500000        2          7  ...   \n",
       "2           2.86               55.045872        2          6  ...   \n",
       "3           0.53               56.206089        2          7  ...   \n",
       "4           0.12               63.829787        2          7  ...   \n",
       "5           0.76               56.074766        2          2  ...   \n",
       "6          -1.92               79.207921        3          5  ...   \n",
       "7           2.26               73.394495        3          5  ...   \n",
       "8           0.62               66.666667        3          0  ...   \n",
       "9          -2.54               58.394161        2          7  ...   \n",
       "10         -1.03               49.896050        1          2  ...   \n",
       "11          2.50               52.631579        1          3  ...   \n",
       "12          1.36               52.516411        1          7  ...   \n",
       "13          0.06               66.115702        3          6  ...   \n",
       "14         -2.14               71.428571        3          5  ...   \n",
       "15         -0.23               75.471698        3          7  ...   \n",
       "16          1.61               34.246575        1          2  ...   \n",
       "17          0.08               76.190476        3          3  ...   \n",
       "18         -1.49               54.669704        1          6  ...   \n",
       "19          1.01               57.831325        2          3  ...   \n",
       "20          2.41               65.040650        3          2  ...   \n",
       "21          1.64               79.734219        3          7  ...   \n",
       "22          1.77               56.872038        2          3  ...   \n",
       "23          0.55               76.433121        3          7  ...   \n",
       "24          1.39               65.040650        3          3  ...   \n",
       "25          1.73               63.157895        2          2  ...   \n",
       "26          0.75               59.113300        2          7  ...   \n",
       "27         -2.40               64.343164        2          3  ...   \n",
       "28          1.65               58.679707        2          2  ...   \n",
       "29          1.79               59.259259        2          7  ...   \n",
       "..           ...                     ...      ...        ...  ...   \n",
       "483        -0.89               60.453401        2          4  ...   \n",
       "484         1.56               60.301508        2          3  ...   \n",
       "485         2.22               61.855670        2          5  ...   \n",
       "486         0.49               66.481994        3          7  ...   \n",
       "487         0.32               80.267559        4          2  ...   \n",
       "488         0.65               62.176166        2          5  ...   \n",
       "489         1.43               60.606061        2          7  ...   \n",
       "490         0.37               53.811659        1          7  ...   \n",
       "491         1.74               57.553957        2          4  ...   \n",
       "492        -1.42               70.588235        3          7  ...   \n",
       "493        -0.72               77.419355        3          7  ...   \n",
       "494         0.05               56.603774        2          5  ...   \n",
       "495         0.95               59.113300        2          4  ...   \n",
       "496         1.52              102.564103        5          3  ...   \n",
       "497         2.30               65.934066        3          5  ...   \n",
       "498         2.06               54.054054        1          0  ...   \n",
       "499        -1.04               28.846154        1          5  ...   \n",
       "500        -1.22               80.808081        4          4  ...   \n",
       "501         2.22               56.074766        2          5  ...   \n",
       "502        -1.17               64.171123        2          3  ...   \n",
       "503        -0.35               66.298343        3          5  ...   \n",
       "504         0.92               62.176166        2          2  ...   \n",
       "505         2.46               65.573770        3          7  ...   \n",
       "506        -0.45               61.381074        2          2  ...   \n",
       "507        -1.41               55.944056        2          3  ...   \n",
       "508        -0.77               78.431373        3          7  ...   \n",
       "509        -0.67               59.850374        2          2  ...   \n",
       "510        -0.05               77.669903        3          3  ...   \n",
       "511         0.89               62.015504        2          7  ...   \n",
       "512        -2.49               55.214724        2          3  ...   \n",
       "\n",
       "     Sleep_weekend  Sleep_percent  Global_sleep_CAT  Household_size  \\\n",
       "0             7.25      95.238095                 1             6.0   \n",
       "1            11.50      95.652174                 0             4.0   \n",
       "2             8.00      91.428571                 1             3.0   \n",
       "3            11.00      76.190476                 1             4.0   \n",
       "4            11.25      98.876404                 0             3.0   \n",
       "5            12.00      70.000000                 1             4.0   \n",
       "6             9.50      95.238095                 0             7.0   \n",
       "7             6.00     100.000000                 1             6.0   \n",
       "8            10.00      70.422535                 1             6.0   \n",
       "9             8.00     100.000000                 1             5.0   \n",
       "10            9.00      94.117647                 1             4.0   \n",
       "11            4.00     100.000000                 1             5.0   \n",
       "12            8.00     100.000000                 1             4.0   \n",
       "13            9.00      97.297297                 0             5.0   \n",
       "14            9.00      75.675676                 1             7.0   \n",
       "15            9.00     100.000000                 0             4.0   \n",
       "16            9.25      91.139241                 0             7.0   \n",
       "17           13.00      53.333333                 1             5.0   \n",
       "18            9.50      75.000000                 1             6.0   \n",
       "19           10.00     100.000000                 0             4.0   \n",
       "20            7.00     100.000000                 1             5.0   \n",
       "21            7.50     100.000000                 1            10.0   \n",
       "22           12.00      74.418605                 1            10.0   \n",
       "23            8.00      96.277279                 0             4.0   \n",
       "24            7.00     100.000000                 0             6.0   \n",
       "25           10.00      80.000000                 1             4.0   \n",
       "26           10.00      88.888889                 1             5.0   \n",
       "27            9.33      67.385445                 1             6.0   \n",
       "28            9.00      70.588235                 1             3.0   \n",
       "29           12.00      72.727273                 1             7.0   \n",
       "..             ...            ...               ...             ...   \n",
       "483           6.50      97.879282                 1             5.0   \n",
       "484           8.00      98.176718                 1             6.0   \n",
       "485          10.00      97.297297                 0             4.0   \n",
       "486           4.50     100.000000                 1             3.0   \n",
       "487           3.50      95.652174                 1             9.0   \n",
       "488           8.00      88.421053                 1             6.0   \n",
       "489          12.50      70.000000                 1             7.0   \n",
       "490          10.00      60.000000                 1             5.0   \n",
       "491           9.00      38.709677                 1             3.0   \n",
       "492           8.50      94.193548                 0             6.0   \n",
       "493           8.00      96.000000                 1            10.0   \n",
       "494           7.25     101.818182                 0            12.0   \n",
       "495          10.00      77.777778                 1             7.0   \n",
       "496          11.00      80.000000                 1             4.0   \n",
       "497           8.00      92.307692                 0             6.0   \n",
       "498           8.00      80.898876                 1             5.0   \n",
       "499          10.17      74.226804                 1             6.0   \n",
       "500           8.00      51.612903                 1             4.0   \n",
       "501          11.00      95.948827                 0             5.0   \n",
       "502           9.00      86.896552                 0             9.0   \n",
       "503           9.50      96.296296                 1             NaN   \n",
       "504           7.00      80.000000                 1             5.0   \n",
       "505           9.00      85.714286                 1             5.0   \n",
       "506          10.50      85.287846                 1             5.0   \n",
       "507          10.00      93.333333                 1             7.0   \n",
       "508           8.00      90.909091                 0             4.0   \n",
       "509          11.00      31.578947                 1             9.0   \n",
       "510           9.00      61.538462                 1             NaN   \n",
       "511           9.00     100.000000                 0             6.0   \n",
       "512           7.50      87.209302                 1             6.0   \n",
       "\n",
       "     Income_CAT  Edu_father  Edu_mother  Interference_score_ALL  WM_total  \\\n",
       "0           2.0         3.0         3.0               10.409091        16   \n",
       "1           3.0         4.0         3.0               -2.697183        16   \n",
       "2           1.0         3.0         2.0                6.598361        16   \n",
       "3           1.0         3.0         4.0                1.454545        15   \n",
       "4           1.0         2.0         3.0                0.291339        15   \n",
       "5           3.0         4.0         4.0                2.657534        17   \n",
       "6           1.0         3.0         3.0                5.225806        26   \n",
       "7           3.0         4.0         4.0                0.939394        13   \n",
       "8           3.0         4.0         4.0               -7.417178        16   \n",
       "9           2.0         3.0         3.0               -3.853659        17   \n",
       "10          3.0         4.0         4.0                3.058824        21   \n",
       "11          2.0         4.0         3.0               10.752212        17   \n",
       "12          2.0         4.0         3.0                2.376812        19   \n",
       "13          1.0         2.0         2.0               -0.285714        18   \n",
       "14          2.0         3.0         4.0                3.495868        15   \n",
       "15          1.0         4.0         4.0                2.654412        19   \n",
       "16          2.0         3.0         4.0                1.836735        12   \n",
       "17          2.0         3.0         3.0                8.000000        12   \n",
       "18          3.0         3.0         3.0                0.500000        16   \n",
       "19          2.0         3.0         3.0                2.219101        25   \n",
       "20          3.0         3.0         4.0               -2.189189        13   \n",
       "21          3.0         4.0         4.0               -6.343284        12   \n",
       "22          1.0         3.0         3.0                0.963768        15   \n",
       "23          2.0         4.0         4.0                9.560000        22   \n",
       "24          1.0         3.0         3.0               -4.014388        18   \n",
       "25          3.0         4.0         4.0                1.376623        16   \n",
       "26          3.0         4.0         4.0                6.801527        14   \n",
       "27          1.0         4.0         4.0               -9.617647        19   \n",
       "28          1.0         3.0         3.0               -8.172414        12   \n",
       "29          2.0         4.0         4.0               -7.935484        17   \n",
       "..          ...         ...         ...                     ...       ...   \n",
       "483         1.0         3.0         3.0                0.222222        16   \n",
       "484         1.0         3.0         3.0               -2.372414        15   \n",
       "485         2.0         3.0         3.0               -1.759036        22   \n",
       "486         2.0         3.0         4.0                3.975610        15   \n",
       "487         1.0         3.0         3.0                3.167630        18   \n",
       "488         2.0         3.0         3.0               -5.655914        17   \n",
       "489         1.0         3.0         2.0                1.942197        20   \n",
       "490         2.0         3.0         3.0               -2.653543        15   \n",
       "491         1.0         3.0         3.0              -11.116279        10   \n",
       "492         2.0         3.0         3.0                5.689655        20   \n",
       "493         1.0         3.0         2.0               12.173611        19   \n",
       "494         2.0         2.0         3.0               -7.670886        20   \n",
       "495         2.0         3.0         3.0                3.000000        16   \n",
       "496         1.0         3.0         3.0                5.564103        16   \n",
       "497         3.0         3.0         3.0               -7.302326        18   \n",
       "498         1.0         3.0         3.0               -3.290323        15   \n",
       "499         2.0         4.0         3.0              -19.459716        18   \n",
       "500         1.0         3.0         3.0                1.943396        11   \n",
       "501         2.0         3.0         3.0               -1.223077        15   \n",
       "502         1.0         3.0         3.0               -1.878788        15   \n",
       "503         NaN         NaN         NaN               -1.228758        14   \n",
       "504         1.0         3.0         3.0                1.000000        16   \n",
       "505         2.0         2.0         3.0               -0.468750        29   \n",
       "506         1.0         3.0         3.0                7.306667        20   \n",
       "507         1.0         3.0         3.0                5.214286        20   \n",
       "508         1.0         3.0         3.0               -0.333333        25   \n",
       "509         1.0         2.0         3.0               -5.154930        19   \n",
       "510         NaN         NaN         NaN                2.600000        18   \n",
       "511         1.0         3.0         3.0                1.469231        16   \n",
       "512         2.0         3.0         2.0                9.479532        17   \n",
       "\n",
       "     CF_total  \n",
       "0       18.00  \n",
       "1       27.00  \n",
       "2        4.31  \n",
       "3       45.16  \n",
       "4       15.07  \n",
       "5       24.40  \n",
       "6       33.00  \n",
       "7       33.96  \n",
       "8       15.70  \n",
       "9       36.99  \n",
       "10      44.00  \n",
       "11      18.60  \n",
       "12      31.00  \n",
       "13      23.00  \n",
       "14      51.00  \n",
       "15      14.24  \n",
       "16      19.00  \n",
       "17      75.71  \n",
       "18      30.77  \n",
       "19      41.56  \n",
       "20       5.10  \n",
       "21     136.62  \n",
       "22      58.00  \n",
       "23      -1.00  \n",
       "24      53.55  \n",
       "25       9.83  \n",
       "26      47.60  \n",
       "27      72.50  \n",
       "28       9.60  \n",
       "29      72.00  \n",
       "..        ...  \n",
       "483     13.03  \n",
       "484     41.00  \n",
       "485     27.00  \n",
       "486     15.24  \n",
       "487     10.53  \n",
       "488     41.00  \n",
       "489     17.67  \n",
       "490     62.40  \n",
       "491     67.00  \n",
       "492     14.91  \n",
       "493     11.00  \n",
       "494     18.00  \n",
       "495     11.00  \n",
       "496     19.80  \n",
       "497     56.17  \n",
       "498      7.88  \n",
       "499     19.00  \n",
       "500     37.00  \n",
       "501      4.60  \n",
       "502      8.90  \n",
       "503      9.28  \n",
       "504     55.00  \n",
       "505     20.68  \n",
       "506     22.86  \n",
       "507     17.50  \n",
       "508     16.79  \n",
       "509     15.00  \n",
       "510     24.00  \n",
       "511     36.70  \n",
       "512     15.30  \n",
       "\n",
       "[513 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicate data (if any)\n",
    "\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 486 entries, 0 to 512\n",
      "Data columns (total 25 columns):\n",
      "Reference_no              486 non-null int64\n",
      "Actual_age_C              486 non-null float64\n",
      "Sex                       486 non-null int64\n",
      "Weight                    486 non-null float64\n",
      "Height_meter              486 non-null float64\n",
      "BMI                       486 non-null float64\n",
      "BMI_for_age               486 non-null float64\n",
      "Physical_fitness_score    486 non-null float64\n",
      "PFS_CAT                   486 non-null int64\n",
      "Breakfast                 486 non-null int64\n",
      "Lunch                     486 non-null int64\n",
      "Dinner                    486 non-null int64\n",
      "PA_total_score            486 non-null float64\n",
      "PA_CAT                    486 non-null int64\n",
      "Sleep_weekdays            486 non-null float64\n",
      "Sleep_weekend             486 non-null float64\n",
      "Sleep_percent             486 non-null float64\n",
      "Global_sleep_CAT          486 non-null int64\n",
      "Household_size            486 non-null float64\n",
      "Income_CAT                486 non-null float64\n",
      "Edu_father                486 non-null float64\n",
      "Edu_mother                486 non-null float64\n",
      "Interference_score_ALL    486 non-null float64\n",
      "WM_total                  486 non-null int64\n",
      "CF_total                  486 non-null float64\n",
      "dtypes: float64(16), int64(9)\n",
      "memory usage: 98.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Drop 27 rows corresponding to 27 missing values\n",
    "# Missing values found in 'Household_size', 'Income_CAT', 'Edu_father', and 'Edu_mother'\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference_no</th>\n",
       "      <th>Actual_age_C</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height_meter</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BMI_for_age</th>\n",
       "      <th>Physical_fitness_score</th>\n",
       "      <th>PFS_CAT</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>...</th>\n",
       "      <th>Sleep_weekend</th>\n",
       "      <th>Sleep_percent</th>\n",
       "      <th>Global_sleep_CAT</th>\n",
       "      <th>Household_size</th>\n",
       "      <th>Income_CAT</th>\n",
       "      <th>Edu_father</th>\n",
       "      <th>Edu_mother</th>\n",
       "      <th>Interference_score_ALL</th>\n",
       "      <th>WM_total</th>\n",
       "      <th>CF_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.069959</td>\n",
       "      <td>14.075512</td>\n",
       "      <td>1.604938</td>\n",
       "      <td>51.867695</td>\n",
       "      <td>1.564756</td>\n",
       "      <td>21.004273</td>\n",
       "      <td>0.221049</td>\n",
       "      <td>62.973417</td>\n",
       "      <td>2.267490</td>\n",
       "      <td>4.213992</td>\n",
       "      <td>...</td>\n",
       "      <td>8.771770</td>\n",
       "      <td>82.883973</td>\n",
       "      <td>0.724280</td>\n",
       "      <td>5.462963</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>3.277778</td>\n",
       "      <td>3.277778</td>\n",
       "      <td>1.340364</td>\n",
       "      <td>17.306584</td>\n",
       "      <td>27.630988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>148.917535</td>\n",
       "      <td>1.322689</td>\n",
       "      <td>0.489368</td>\n",
       "      <td>14.870932</td>\n",
       "      <td>0.080929</td>\n",
       "      <td>5.089657</td>\n",
       "      <td>1.515608</td>\n",
       "      <td>12.155276</td>\n",
       "      <td>0.975183</td>\n",
       "      <td>2.392318</td>\n",
       "      <td>...</td>\n",
       "      <td>2.006336</td>\n",
       "      <td>17.249667</td>\n",
       "      <td>0.447337</td>\n",
       "      <td>1.614901</td>\n",
       "      <td>0.807184</td>\n",
       "      <td>0.577053</td>\n",
       "      <td>0.587674</td>\n",
       "      <td>6.563426</td>\n",
       "      <td>3.762901</td>\n",
       "      <td>19.443671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.106776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>1.365000</td>\n",
       "      <td>12.988233</td>\n",
       "      <td>-3.950000</td>\n",
       "      <td>19.543974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>19.317450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-20.792857</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>127.250000</td>\n",
       "      <td>12.985626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.600000</td>\n",
       "      <td>1.508125</td>\n",
       "      <td>17.328972</td>\n",
       "      <td>-0.885000</td>\n",
       "      <td>55.813953</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>74.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.850857</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>256.500000</td>\n",
       "      <td>13.655031</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>1.558500</td>\n",
       "      <td>19.850710</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>60.913706</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.946207</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>385.750000</td>\n",
       "      <td>15.482546</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>58.950000</td>\n",
       "      <td>1.618625</td>\n",
       "      <td>23.462314</td>\n",
       "      <td>1.267500</td>\n",
       "      <td>69.114578</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.245677</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>36.207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>513.000000</td>\n",
       "      <td>16.970000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>117.500000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>42.743375</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>126.315789</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>101.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.471264</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>136.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reference_no  Actual_age_C         Sex      Weight  Height_meter  \\\n",
       "count    486.000000    486.000000  486.000000  486.000000    486.000000   \n",
       "mean     256.069959     14.075512    1.604938   51.867695      1.564756   \n",
       "std      148.917535      1.322689    0.489368   14.870932      0.080929   \n",
       "min        1.000000     12.106776    1.000000   24.200000      1.365000   \n",
       "25%      127.250000     12.985626    1.000000   41.600000      1.508125   \n",
       "50%      256.500000     13.655031    2.000000   48.800000      1.558500   \n",
       "75%      385.750000     15.482546    2.000000   58.950000      1.618625   \n",
       "max      513.000000     16.970000    2.000000  117.500000      1.875000   \n",
       "\n",
       "              BMI  BMI_for_age  Physical_fitness_score     PFS_CAT  \\\n",
       "count  486.000000   486.000000              486.000000  486.000000   \n",
       "mean    21.004273     0.221049               62.973417    2.267490   \n",
       "std      5.089657     1.515608               12.155276    0.975183   \n",
       "min     12.988233    -3.950000               19.543974    1.000000   \n",
       "25%     17.328972    -0.885000               55.813953    2.000000   \n",
       "50%     19.850710     0.235000               60.913706    2.000000   \n",
       "75%     23.462314     1.267500               69.114578    3.000000   \n",
       "max     42.743375     4.160000              126.315789    5.000000   \n",
       "\n",
       "        Breakfast  ...  Sleep_weekend  Sleep_percent  Global_sleep_CAT  \\\n",
       "count  486.000000  ...     486.000000     486.000000        486.000000   \n",
       "mean     4.213992  ...       8.771770      82.883973          0.724280   \n",
       "std      2.392318  ...       2.006336      17.249667          0.447337   \n",
       "min      0.000000  ...       2.500000      19.317450          0.000000   \n",
       "25%      2.000000  ...       7.500000      74.074074          0.000000   \n",
       "50%      4.000000  ...       9.000000      87.500000          1.000000   \n",
       "75%      7.000000  ...      10.000000      96.774194          1.000000   \n",
       "max      7.000000  ...      14.000000     101.818182          1.000000   \n",
       "\n",
       "       Household_size  Income_CAT  Edu_father  Edu_mother  \\\n",
       "count      486.000000  486.000000  486.000000  486.000000   \n",
       "mean         5.462963    1.888889    3.277778    3.277778   \n",
       "std          1.614901    0.807184    0.577053    0.587674   \n",
       "min          2.000000    1.000000    1.000000    1.000000   \n",
       "25%          4.000000    1.000000    3.000000    3.000000   \n",
       "50%          5.000000    2.000000    3.000000    3.000000   \n",
       "75%          6.000000    3.000000    4.000000    4.000000   \n",
       "max         12.000000    3.000000    4.000000    4.000000   \n",
       "\n",
       "       Interference_score_ALL    WM_total    CF_total  \n",
       "count              486.000000  486.000000  486.000000  \n",
       "mean                 1.340364   17.306584   27.630988  \n",
       "std                  6.563426    3.762901   19.443671  \n",
       "min                -20.792857   10.000000  -15.000000  \n",
       "25%                 -2.850857   15.000000   14.392500  \n",
       "50%                  0.946207   17.000000   23.000000  \n",
       "75%                  5.245677   19.000000   36.207500  \n",
       "max                 27.471264   30.000000  136.620000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "\n",
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interference Score Mean = 1.3403639929392468\n",
      "Working Memory Score Mean = 17.30658436213992\n",
      "Cognitive Flexibililty Score Mean = 27.630987654320986\n"
     ]
    }
   ],
   "source": [
    "# Means of EF Scores\n",
    "\n",
    "INT_mean = np.mean(df_cleaned['Interference_score_ALL'])\n",
    "print('Interference Score Mean = ' + str(INT_mean))\n",
    "\n",
    "WM_mean = np.mean(df_cleaned['WM_total'])\n",
    "print('Working Memory Score Mean = ' + str(WM_mean))\n",
    "\n",
    "CF_mean = np.mean(df_cleaned['CF_total'])\n",
    "print('Cognitive Flexibililty Score Mean = ' + str(CF_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sex vs. EF Scores (2)**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: $Î¼_{male}$ = $Î¼_{female}$\n",
    "\n",
    "$H_{a}$: $Î¼_{male}$ != $Î¼_{female}$\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: $Î¼_{male}$ = $Î¼_{female}$\n",
    "\n",
    "$H_{a}$: $Î¼_{male}$ != $Î¼_{female}$\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: $Î¼_{male}$ = $Î¼_{female}$\n",
    "\n",
    "$H_{a}$: $Î¼_{male}$ != $Î¼_{female}$\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.5966053029252087, pvalue=0.5510498745067827)\n",
      "Ttest_indResult(statistic=-0.7113926106938543, pvalue=0.4771836859720252)\n",
      "Ttest_indResult(statistic=2.5569918736996926, pvalue=0.010862087919187921)\n"
     ]
    }
   ],
   "source": [
    "# Two-Sample T-Tests - Male vs. Female\n",
    "\n",
    "male = df_cleaned[df_cleaned['Sex']==1]\n",
    "female = df_cleaned[df_cleaned['Sex']==2]\n",
    "\n",
    "## Interference\n",
    "\n",
    "sex_INT = stats.ttest_ind(male['Interference_score_ALL'], female['Interference_score_ALL'], equal_var=True)\n",
    "print(sex_INT)\n",
    "\n",
    "## Working Memory\n",
    "\n",
    "sex_WM = stats.ttest_ind(male['WM_total'], female['WM_total'], equal_var=True)\n",
    "print(sex_WM)\n",
    "\n",
    "\n",
    "## Cognitive Flexibility\n",
    "\n",
    "sex_CF = stats.ttest_ind(male['CF_total'], female['CF_total'], equal_var=True)\n",
    "print(sex_CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis can be rejected for sex with cognitive flexibility - the mean CF scores are statistically different for males and females. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global_Sleep_CAT vs. EF Scores (2)**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: $Î¼_{poor}$ = $Î¼_{good}$\n",
    "\n",
    "$H_{a}$: $Î¼_{poor}$ != $Î¼_{good}$\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: $Î¼_{poor}$ = $Î¼_{good}$\n",
    "\n",
    "$H_{a}$: $Î¼_{poor}$ != $Î¼_{good}$\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: $Î¼_{poor}$ = $Î¼_{good}$\n",
    "\n",
    "$H_{a}$: $Î¼_{poor}$ != $Î¼_{good}$\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.7496796784556222, pvalue=0.45381188018109764)\n",
      "Ttest_indResult(statistic=3.378455827316496, pvalue=0.0007877686104364707)\n",
      "Ttest_indResult(statistic=-0.6377294566326531, pvalue=0.5239513848910329)\n"
     ]
    }
   ],
   "source": [
    "# Two-Sample T-Tests - 0 (Poor Sleep Quality) vs. 1 (Good Sleep Quality)\n",
    "\n",
    "poor_sleep = df_cleaned[df_cleaned['Global_sleep_CAT']==0]\n",
    "good_sleep = df_cleaned[df_cleaned['Global_sleep_CAT']==1]\n",
    "\n",
    "## Interference\n",
    "\n",
    "sleep_INT = stats.ttest_ind(poor_sleep['Interference_score_ALL'], good_sleep['Interference_score_ALL'], equal_var=True)\n",
    "print(sleep_INT)\n",
    "\n",
    "## Working Memory\n",
    "\n",
    "sleep_WM = stats.ttest_ind(poor_sleep['WM_total'], good_sleep['WM_total'], equal_var=True)\n",
    "print(sleep_WM)\n",
    "\n",
    "\n",
    "## Cognitive Flexibility\n",
    "\n",
    "sleep_CF = stats.ttest_ind(poor_sleep['CF_total'], good_sleep['CF_total'], equal_var=True)\n",
    "print(sleep_CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis can be rejected for global sleep category with working memory - those who fall into the \"good sleep quality\" category exhibit statistically significant working memory scores than those who fall into the \"poor sleep quality\" category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PFS_CAT vs. EF Scores (5)**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: $Î¼_{1}$ = $Î¼_{2}$ = $Î¼_{3}$ = $Î¼_{4}$ = $Î¼_{5}$ \n",
    "\n",
    "$H_{a}$: At least one inequality exists between the means \n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: $Î¼_{1}$ = $Î¼_{2}$ = $Î¼_{3}$ = $Î¼_{4}$ = $Î¼_{5}$\n",
    "\n",
    "$H_{a}$: At least one inequality exists between the means \n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: $Î¼_{1}$ = $Î¼_{2}$ = $Î¼_{3}$ = $Î¼_{4}$ = $Î¼_{5}$\n",
    "\n",
    "$H_{a}$: At least one inequality exists between the means \n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFS_CAT vs. Interference\n",
    "\n",
    "CAT1 = (df_cleaned['PFS_CAT']==1)\n",
    "PFS_CAT1_int = df_cleaned[CAT1].Interference_score_ALL\n",
    "\n",
    "CAT2 = (df_cleaned['PFS_CAT']==2)\n",
    "PFS_CAT2_int = df_cleaned[CAT2].Interference_score_ALL\n",
    "\n",
    "CAT3 = (df_cleaned['PFS_CAT']==3)\n",
    "PFS_CAT3_int = df_cleaned[CAT3].Interference_score_ALL\n",
    "\n",
    "CAT4 = (df_cleaned['PFS_CAT']==4)\n",
    "PFS_CAT4_int = df_cleaned[CAT4].Interference_score_ALL\n",
    "\n",
    "CAT5 = (df_cleaned['PFS_CAT']==5)\n",
    "PFS_CAT5_int = df_cleaned[CAT5].Interference_score_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assumption 1 - Normality\n",
    "\n",
    "_ = plt.hist(df_cleaned.Interference_score_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assumption 1 - Normality, cont'd\n",
    "\n",
    "_ = plt.hist(df_cleaned.Interference_score_ALL.apply(lambda x: np.log(x+20.8)), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1 Variance 36.7276288757642\n",
      "Category 2 Variance 40.89471242092129\n",
      "Category 3 Variance 53.870182273174194\n",
      "Category 4 Variance 31.040249851321327\n",
      "Category 5 Variance 39.07503533466261\n"
     ]
    }
   ],
   "source": [
    "# Assumption #2 - Category Variances\n",
    "\n",
    "var_CAT1 = np.var(PFS_CAT1_int)\n",
    "print('Category 1 Variance ' + str(var_CAT1))\n",
    "\n",
    "var_CAT2 = np.var(PFS_CAT2_int)\n",
    "print('Category 2 Variance ' + str(var_CAT2))\n",
    "\n",
    "var_CAT3 = np.var(PFS_CAT3_int)\n",
    "print('Category 3 Variance ' + str(var_CAT3))\n",
    "\n",
    "var_CAT4 = np.var(PFS_CAT4_int)\n",
    "print('Category 4 Variance ' + str(var_CAT4))\n",
    "\n",
    "var_CAT5 = np.var(PFS_CAT5_int)\n",
    "print('Category 5 Variance ' + str(var_CAT5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANOVA condition regarding homogeneity of variances is not robust - the sample variances must be equal. The Levene Test is conducted to test the null hypothesis that all input samples are from populations with equal variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=1.6199039767391505, pvalue=0.16798661131019235)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.levene(PFS_CAT1_int, PFS_CAT2_int, PFS_CAT3_int, PFS_CAT4_int, PFS_CAT5_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis cannot be rejected for the 0.01 or 0.05 significance levels, making the One-Factor ANOVA an inappropriate test to determine significance. Welch's t-test can be conducted to calculate an alternate F statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFS_CAT1_2 = Ttest_indResult(statistic=0.33723405574558907, pvalue=0.7362692543073234)\n",
      "PFS_CAT1_3 = Ttest_indResult(statistic=-0.6265479533779522, pvalue=0.5315797303500712)\n",
      "PFS_CAT1_4 = Ttest_indResult(statistic=0.22861483281009928, pvalue=0.8201993431849939)\n",
      "PFS_CAT1_5 = Ttest_indResult(statistic=1.0951334163998574, pvalue=0.2858926668187994)\n",
      "PFS_CAT2_3 = Ttest_indResult(statistic=-1.020249062282733, pvalue=0.3086475884977169)\n",
      "PFS_CAT2_4 = Ttest_indResult(statistic=0.025834392789445687, pvalue=0.9795288847336916)\n",
      "PFS_CAT2_5 = Ttest_indResult(statistic=0.9737384480166577, pvalue=0.34264295978414083)\n",
      "PFS_CAT3_4 = Ttest_indResult(statistic=0.665191492226989, pvalue=0.509024764307876)\n",
      "PFS_CAT3_5 = Ttest_indResult(statistic=1.409018863567933, pvalue=0.17280360321223115)\n",
      "PFS_CAT4_5 = Ttest_indResult(statistic=0.8186583559970402, pvalue=0.41931309223648006)\n"
     ]
    }
   ],
   "source": [
    "# Multiple T-Tests (Welch's Test) for PFS_CAT vs. Interference\n",
    "\n",
    "# CAT 1 - \"Poor\"\n",
    "\n",
    "PFS_CAT1_2 = stats.ttest_ind(PFS_CAT1_int, PFS_CAT2_int, equal_var=False)\n",
    "print('PFS_CAT1_2 = ' + str(PFS_CAT1_2))\n",
    "\n",
    "PFS_CAT1_3 = stats.ttest_ind(PFS_CAT1_int, PFS_CAT3_int, equal_var=False)\n",
    "print('PFS_CAT1_3 = ' + str(PFS_CAT1_3))\n",
    "\n",
    "PFS_CAT1_4 = stats.ttest_ind(PFS_CAT1_int, PFS_CAT4_int, equal_var=False)\n",
    "print('PFS_CAT1_4 = ' + str(PFS_CAT1_4))\n",
    "\n",
    "PFS_CAT1_5 = stats.ttest_ind(PFS_CAT1_int, PFS_CAT5_int, equal_var=False)\n",
    "print('PFS_CAT1_5 = ' + str(PFS_CAT1_5))\n",
    "\n",
    "# CAT 2 - \"Low Average\"\n",
    "\n",
    "PFS_CAT2_3 = stats.ttest_ind(PFS_CAT2_int, PFS_CAT3_int, equal_var=False)\n",
    "print('PFS_CAT2_3 = ' + str(PFS_CAT2_3))\n",
    "\n",
    "PFS_CAT2_4 = stats.ttest_ind(PFS_CAT2_int, PFS_CAT4_int, equal_var=False)\n",
    "print('PFS_CAT2_4 = ' + str(PFS_CAT2_4))\n",
    "\n",
    "PFS_CAT2_5 = stats.ttest_ind(PFS_CAT2_int, PFS_CAT5_int, equal_var=False)\n",
    "print('PFS_CAT2_5 = ' + str(PFS_CAT2_5))\n",
    "\n",
    "# CAT 3 - \"High Average\"\n",
    "\n",
    "PFS_CAT3_4 = stats.ttest_ind(PFS_CAT3_int, PFS_CAT4_int, equal_var=False)\n",
    "print('PFS_CAT3_4 = ' + str(PFS_CAT3_4))\n",
    "\n",
    "PFS_CAT3_5 = stats.ttest_ind(PFS_CAT3_int, PFS_CAT5_int, equal_var=False)\n",
    "print('PFS_CAT3_5 = ' + str(PFS_CAT3_5))\n",
    "\n",
    "# CAT 4 - \"Good\"\n",
    "\n",
    "PFS_CAT4_5 = stats.ttest_ind(PFS_CAT4_int, PFS_CAT5_int, equal_var=False)\n",
    "print('PFS_CAT4_5 = ' + str(PFS_CAT4_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all p-values > Î± (0.05), the null hypothesis cannot be rejected. There is no significant difference between the five group means with respect to interference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFS_CAT vs. Working Memory\n",
    "\n",
    "PFS_CAT1_WM = df_cleaned[CAT1].WM_total\n",
    "\n",
    "PFS_CAT2_WM = df_cleaned[CAT2].WM_total\n",
    "\n",
    "PFS_CAT3_WM = df_cleaned[CAT3].WM_total\n",
    "\n",
    "PFS_CAT4_WM = df_cleaned[CAT4].WM_total\n",
    "\n",
    "PFS_CAT5_WM = df_cleaned[CAT5].WM_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(df_cleaned.WM_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the data is skewed, ANOVA is appropriate as long as variances are equal and the model is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.32159667167382805, pvalue=0.8635202961909922)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levene Test\n",
    "\n",
    "stats.levene(PFS_CAT1_WM, PFS_CAT2_WM, PFS_CAT3_WM, PFS_CAT4_WM, PFS_CAT5_WM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFS_WM_1_2 = Ttest_indResult(statistic=1.1056360151088664, pvalue=0.27030156073645284)\n",
      "PFS_WM_1_3 = Ttest_indResult(statistic=0.1487732865163074, pvalue=0.8818692471625802)\n",
      "PFS_WM_1_4 = Ttest_indResult(statistic=1.1336316774989315, pvalue=0.26356736723146984)\n",
      "PFS_WM_1_5 = Ttest_indResult(statistic=-0.09416137199983304, pvalue=0.9259152826659935)\n",
      "PFS_WM_2_3 = Ttest_indResult(statistic=-1.0102956931108242, pvalue=0.3133453366152576)\n",
      "PFS_WM_2_4 = Ttest_indResult(statistic=0.5947784399111334, pvalue=0.5561262766873664)\n",
      "PFS_WM_2_5 = Ttest_indResult(statistic=-0.5417971563145056, pvalue=0.5947565239181918)\n",
      "PFS_WM_3_4 = Ttest_indResult(statistic=1.066319729190738, pvalue=0.2930015388459206)\n",
      "PFS_WM_3_5 = Ttest_indResult(statistic=-0.16150080342297568, pvalue=0.8733830790268036)\n",
      "PFS_WM_4_5 = Ttest_indResult(statistic=-0.813065243256788, pvalue=0.42227564015922747)\n"
     ]
    }
   ],
   "source": [
    "# Multiple T-Tests (Welch's Test) for PFS_CAT vs. Working Memory\n",
    "\n",
    "# CAT 1 - \"Poor\"\n",
    "\n",
    "PFS_WM_1_2 = stats.ttest_ind(PFS_CAT1_WM, PFS_CAT2_WM, equal_var=False)\n",
    "print('PFS_WM_1_2 = ' + str(PFS_WM_1_2))\n",
    "\n",
    "PFS_WM_1_3 = stats.ttest_ind(PFS_CAT1_WM, PFS_CAT3_WM, equal_var=False)\n",
    "print('PFS_WM_1_3 = ' + str(PFS_WM_1_3))\n",
    "\n",
    "PFS_WM_1_4 = stats.ttest_ind(PFS_CAT1_WM, PFS_CAT4_WM, equal_var=False)\n",
    "print('PFS_WM_1_4 = ' + str(PFS_WM_1_4))\n",
    "\n",
    "PFS_WM_1_5 = stats.ttest_ind(PFS_CAT1_WM, PFS_CAT5_WM, equal_var=False)\n",
    "print('PFS_WM_1_5 = ' + str(PFS_WM_1_5))\n",
    "\n",
    "# CAT 2 - \"Low Average\"\n",
    "\n",
    "PFS_WM_2_3 = stats.ttest_ind(PFS_CAT2_WM, PFS_CAT3_WM, equal_var=False)\n",
    "print('PFS_WM_2_3 = ' + str(PFS_WM_2_3))\n",
    "\n",
    "PFS_WM_2_4 = stats.ttest_ind(PFS_CAT2_WM, PFS_CAT4_WM, equal_var=False)\n",
    "print('PFS_WM_2_4 = ' + str(PFS_WM_2_4))\n",
    "\n",
    "PFS_WM_2_5 = stats.ttest_ind(PFS_CAT2_WM, PFS_CAT5_WM, equal_var=False)\n",
    "print('PFS_WM_2_5 = ' + str(PFS_WM_2_5))\n",
    "\n",
    "# CAT 3 - \"High Average\"\n",
    "\n",
    "PFS_WM_3_4 = stats.ttest_ind(PFS_CAT3_WM, PFS_CAT4_WM, equal_var=False)\n",
    "print('PFS_WM_3_4 = ' + str(PFS_WM_3_4))\n",
    "\n",
    "PFS_WM_3_5 = stats.ttest_ind(PFS_CAT3_WM, PFS_CAT5_WM, equal_var=False)\n",
    "print('PFS_WM_3_5 = ' + str(PFS_WM_3_5))\n",
    "\n",
    "# CAT 4 - \"Good\"\n",
    "\n",
    "PFS_WM_4_5 = stats.ttest_ind(PFS_CAT4_WM, PFS_CAT5_WM, equal_var=False)\n",
    "print('PFS_WM_4_5 = ' + str(PFS_WM_4_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis cannot be rejected - there is no significant difference between the five group means with respect to working memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFS_CAT vs. Cognitive Flexibility\n",
    "\n",
    "PFS_CAT1_CF = df_cleaned[CAT1].CF_total\n",
    "\n",
    "PFS_CAT2_CF = df_cleaned[CAT2].CF_total\n",
    "\n",
    "PFS_CAT3_CF = df_cleaned[CAT3].CF_total\n",
    "\n",
    "PFS_CAT4_CF = df_cleaned[CAT4].CF_total\n",
    "\n",
    "PFS_CAT5_CF = df_cleaned[CAT5].CF_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assumption 1 - Normality\n",
    "\n",
    "_ = plt.hist(df_cleaned.CF_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assumption 1 - Normality, cont'd\n",
    "\n",
    "_ = plt.hist(df_cleaned.CF_total.apply(lambda x: np.log(x+15.1)), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.1475342814326341, pvalue=0.9640585052702206)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levene Test\n",
    "\n",
    "stats.levene(PFS_CAT1_CF, PFS_CAT2_CF, PFS_CAT3_CF, PFS_CAT4_CF, PFS_CAT5_CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFS_CF_1_2 = Ttest_indResult(statistic=0.13513850657476428, pvalue=0.892654562579936)\n",
      "PFS_CF_1_3 = Ttest_indResult(statistic=-0.12139343748250023, pvalue=0.9034902685622774)\n",
      "PFS_CF_1_4 = Ttest_indResult(statistic=0.3041332884746812, pvalue=0.762211036564538)\n",
      "PFS_CF_1_5 = Ttest_indResult(statistic=-1.6258187960865955, pvalue=0.11583218490285127)\n",
      "PFS_CF_2_3 = Ttest_indResult(statistic=-0.29644094931377624, pvalue=0.7671566219878602)\n",
      "PFS_CF_2_4 = Ttest_indResult(statistic=0.24216088895216992, pvalue=0.8100279304367719)\n",
      "PFS_CF_2_5 = Ttest_indResult(statistic=-1.8410779824064492, pvalue=0.08084640983146331)\n",
      "PFS_CF_3_4 = Ttest_indResult(statistic=0.4061783923211164, pvalue=0.6863983531198868)\n",
      "PFS_CF_3_5 = Ttest_indResult(statistic=-1.5814513355037416, pvalue=0.1266296625199668)\n",
      "PFS_CF_4_5 = Ttest_indResult(statistic=-1.662642605741499, pvalue=0.10524868990645395)\n"
     ]
    }
   ],
   "source": [
    "# Multiple T-Tests (Welch's Test) for PFS_CAT vs. Cognitive Flexibility\n",
    "\n",
    "# CAT 1 - \"Poor\"\n",
    "\n",
    "PFS_CF_1_2 = stats.ttest_ind(PFS_CAT1_CF, PFS_CAT2_CF, equal_var=False)\n",
    "print('PFS_CF_1_2 = ' + str(PFS_CF_1_2))\n",
    "\n",
    "PFS_CF_1_3 = stats.ttest_ind(PFS_CAT1_CF, PFS_CAT3_CF, equal_var=False)\n",
    "print('PFS_CF_1_3 = ' + str(PFS_CF_1_3))\n",
    "\n",
    "PFS_CF_1_4 = stats.ttest_ind(PFS_CAT1_CF, PFS_CAT4_CF, equal_var=False)\n",
    "print('PFS_CF_1_4 = ' + str(PFS_CF_1_4))\n",
    "\n",
    "PFS_CF_1_5 = stats.ttest_ind(PFS_CAT1_CF, PFS_CAT5_CF, equal_var=False)\n",
    "print('PFS_CF_1_5 = ' + str(PFS_CF_1_5))\n",
    "\n",
    "# CAT 2 - \"Low Average\"\n",
    "\n",
    "PFS_CF_2_3 = stats.ttest_ind(PFS_CAT2_CF, PFS_CAT3_CF, equal_var=False)\n",
    "print('PFS_CF_2_3 = ' + str(PFS_CF_2_3))\n",
    "\n",
    "PFS_CF_2_4 = stats.ttest_ind(PFS_CAT2_CF, PFS_CAT4_CF, equal_var=False)\n",
    "print('PFS_CF_2_4 = ' + str(PFS_CF_2_4))\n",
    "\n",
    "PFS_CF_2_5 = stats.ttest_ind(PFS_CAT2_CF, PFS_CAT5_CF, equal_var=False)\n",
    "print('PFS_CF_2_5 = ' + str(PFS_CF_2_5))\n",
    "\n",
    "# CAT 3 - \"High Average\"\n",
    "\n",
    "PFS_CF_3_4 = stats.ttest_ind(PFS_CAT3_CF, PFS_CAT4_CF, equal_var=False)\n",
    "print('PFS_CF_3_4 = ' + str(PFS_CF_3_4))\n",
    "\n",
    "PFS_CF_3_5 = stats.ttest_ind(PFS_CAT3_CF, PFS_CAT5_CF, equal_var=False)\n",
    "print('PFS_CF_3_5 = ' + str(PFS_CF_3_5))\n",
    "\n",
    "# CAT 4 - \"Good\"\n",
    "\n",
    "PFS_CF_4_5 = stats.ttest_ind(PFS_CAT4_CF, PFS_CAT5_CF, equal_var=False)\n",
    "print('PFS_CF_4_5 = ' + str(PFS_CF_4_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis cannot be rejected - there is no significant difference between the five group means with respect to cognitive flexiblity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PA_CAT vs. EF Scores (3)**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: $Î¼_{1}$ = $Î¼_{2}$ = $Î¼_{3}$\n",
    "\n",
    "$H_{a}$: At least one inequality exists between the means \n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: $Î¼_{1}$ = $Î¼_{2}$ = $Î¼_{3}$\n",
    "\n",
    "$H_{a}$: At least one inequality exists between the means \n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: $Î¼_{1}$ = $Î¼_{2}$ = $Î¼_{3}$\n",
    "\n",
    "$H_{a}$: At least one inequality exists between the means \n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_CAT vs. Interference\n",
    "\n",
    "PA_CAT1 = (df_cleaned['PA_CAT']==1)\n",
    "PA_CAT1_int = df_cleaned[PA_CAT1].Interference_score_ALL\n",
    "\n",
    "PA_CAT2 = (df_cleaned['PA_CAT']==2)\n",
    "PA_CAT2_int = df_cleaned[PA_CAT2].Interference_score_ALL\n",
    "\n",
    "PA_CAT3 = (df_cleaned['PA_CAT']==3)\n",
    "PA_CAT3_int = df_cleaned[PA_CAT3].Interference_score_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.9023555550335898, pvalue=0.40629575092410475)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levene Test\n",
    "\n",
    "stats.levene(PA_CAT1_int, PA_CAT2_int, PA_CAT3_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA_CAT_1_2 = Ttest_indResult(statistic=0.045513048490437316, pvalue=0.963721077338835)\n",
      "PA_CAT_1_3 = Ttest_indResult(statistic=1.4238081623724677, pvalue=0.16362828626281364)\n",
      "PA_CAT_2_3 = Ttest_indResult(statistic=1.4281601175600154, pvalue=0.16295800509791308)\n"
     ]
    }
   ],
   "source": [
    "# Multiple T-Tests (Welch's Test) for PA_CAT vs. Interference\n",
    "\n",
    "# CAT 1 - \"Low Level\"\n",
    "\n",
    "PA_CAT_1_2 = stats.ttest_ind(PA_CAT1_int, PA_CAT2_int, equal_var=False)\n",
    "print('PA_CAT_1_2 = ' + str(PA_CAT_1_2))\n",
    "\n",
    "PA_CAT_1_3 = stats.ttest_ind(PA_CAT1_int, PA_CAT3_int, equal_var=False)\n",
    "print('PA_CAT_1_3 = ' + str(PA_CAT_1_3))\n",
    "\n",
    "\n",
    "# CAT 2 - \"Low Average\"\n",
    "\n",
    "PA_CAT_2_3 = stats.ttest_ind(PA_CAT2_int, PA_CAT3_int, equal_var=False)\n",
    "print('PA_CAT_2_3 = ' + str(PA_CAT_2_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis cannot be rejected - there is no significant difference between the three group means with respect to interference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_CAT vs. Working Memory\n",
    "\n",
    "PA_CAT1_WM = df_cleaned[PA_CAT1].WM_total\n",
    "\n",
    "PA_CAT2_WM = df_cleaned[PA_CAT2].WM_total\n",
    "\n",
    "PA_CAT3_WM = df_cleaned[PA_CAT3].WM_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.6155346481117017, pvalue=0.5407752386453477)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levene Test\n",
    "\n",
    "stats.levene(PA_CAT1_WM, PA_CAT2_WM, PA_CAT3_WM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA_WM_1_2 = Ttest_indResult(statistic=1.0435542225053047, pvalue=0.2973351509616305)\n",
      "PA_WM_1_3 = Ttest_indResult(statistic=-1.4016187337166315, pvalue=0.1697628460422337)\n",
      "PA_WM_2_3 = Ttest_indResult(statistic=-1.8827185765051275, pvalue=0.06872184976594055)\n"
     ]
    }
   ],
   "source": [
    "# Multiple T-Tests (Welch's Test) for PA_CAT vs. Working Memory\n",
    "\n",
    "# CAT 1 - \"Low Level\"\n",
    "\n",
    "PA_WM_1_2 = stats.ttest_ind(PA_CAT1_WM, PA_CAT2_WM, equal_var=False)\n",
    "print('PA_WM_1_2 = ' + str(PA_WM_1_2))\n",
    "\n",
    "PA_WM_1_3 = stats.ttest_ind(PA_CAT1_WM, PA_CAT3_WM, equal_var=False)\n",
    "print('PA_WM_1_3 = ' + str(PA_WM_1_3))\n",
    "\n",
    "\n",
    "# CAT 2 - \"Low Average\"\n",
    "\n",
    "PA_WM_2_3 = stats.ttest_ind(PA_CAT2_WM, PA_CAT3_WM, equal_var=False)\n",
    "print('PA_WM_2_3 = ' + str(PA_WM_2_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis cannot be rejected - there is no significant difference between the three group means with respect to working memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_CAT vs. Cognitive Flexibility\n",
    "\n",
    "PA_CAT1_CF = df_cleaned[PA_CAT1].CF_total\n",
    "\n",
    "PA_CAT2_CF = df_cleaned[PA_CAT2].CF_total\n",
    "\n",
    "PA_CAT3_CF = df_cleaned[PA_CAT3].CF_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.37440260041032986, pvalue=0.687899396435361)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levene Test\n",
    "\n",
    "stats.levene(PA_CAT1_CF, PA_CAT2_CF, PA_CAT3_CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA_CF_1_2 = Ttest_indResult(statistic=-1.9265361444167999, pvalue=0.05470507776836398)\n",
      "PA_CF_1_3 = Ttest_indResult(statistic=-0.9443358591034609, pvalue=0.35114165022958077)\n",
      "PA_CF_2_3 = Ttest_indResult(statistic=-0.0070467959870727775, pvalue=0.9944172821119242)\n"
     ]
    }
   ],
   "source": [
    "# Multiple T-Tests (Welch's Test) for PA_CAT vs. Cognitive Flexibility\n",
    "\n",
    "# CAT 1 - \"Low Level\"\n",
    "\n",
    "PA_CF_1_2 = stats.ttest_ind(PA_CAT1_CF, PA_CAT2_CF, equal_var=False)\n",
    "print('PA_CF_1_2 = ' + str(PA_CF_1_2))\n",
    "\n",
    "PA_CF_1_3 = stats.ttest_ind(PA_CAT1_CF, PA_CAT3_CF, equal_var=False)\n",
    "print('PA_CF_1_3 = ' + str(PA_CF_1_3))\n",
    "\n",
    "\n",
    "# CAT 2 - \"Low Average\"\n",
    "\n",
    "PA_CF_2_3 = stats.ttest_ind(PA_CAT2_CF, PA_CAT3_CF, equal_var=False)\n",
    "print('PA_CF_2_3 = ' + str(PA_CF_2_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis cannot be rejected - there is no significant difference between the three group means with respect to cognitive flexilibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income Category vs. EF Scores (3)**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: $Î¼_{1}$ = $Î¼_{2}$ = $Î¼_{3}$\n",
    "\n",
    "$H_{a}$: At least one inequality exists between the means \n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: $Î¼_{1}$ = $Î¼_{2}$ = $Î¼_{3}$\n",
    "\n",
    "$H_{a}$: At least one inequality exists between the means \n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: $Î¼_{1}$ = $Î¼_{2}$ = $Î¼_{3}$\n",
    "\n",
    "$H_{a}$: At least one inequality exists between the means \n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income_CAT vs. Interference\n",
    "\n",
    "INC_CAT1 = (df_cleaned['Income_CAT']==1)\n",
    "INC_CAT1_int = df_cleaned[INC_CAT1].Interference_score_ALL\n",
    "\n",
    "INC_CAT2 = (df_cleaned['Income_CAT']==2)\n",
    "INC_CAT2_int = df_cleaned[INC_CAT2].Interference_score_ALL\n",
    "\n",
    "INC_CAT3 = (df_cleaned['Income_CAT']==3)\n",
    "INC_CAT3_int = df_cleaned[INC_CAT3].Interference_score_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.2309361515390163, pvalue=0.7938777437762871)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levene Test\n",
    "\n",
    "stats.levene(INC_CAT1_int, INC_CAT2_int, INC_CAT3_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INC_CAT_1_2 = Ttest_indResult(statistic=-0.8637930134838726, pvalue=0.38831061318183946)\n",
      "INC_CAT_1_3 = Ttest_indResult(statistic=-1.9948485792545718, pvalue=0.047049241489114685)\n",
      "INC_CAT_2_3 = Ttest_indResult(statistic=-1.1475711548775827, pvalue=0.2521244363467227)\n"
     ]
    }
   ],
   "source": [
    "# Multiple T-Tests (Welch's Test) for Income_CAT vs. Interference\n",
    "\n",
    "# CAT 1 - RM < 2300\n",
    "\n",
    "INC_CAT_1_2 = stats.ttest_ind(INC_CAT1_int, INC_CAT2_int, equal_var=False)\n",
    "print('INC_CAT_1_2 = ' + str(INC_CAT_1_2))\n",
    "\n",
    "INC_CAT_1_3 = stats.ttest_ind(INC_CAT1_int, INC_CAT3_int, equal_var=False)\n",
    "print('INC_CAT_1_3 = ' + str(INC_CAT_1_3))\n",
    "\n",
    "\n",
    "# CAT 2 - \"2300 - RM - 5599\"\n",
    "\n",
    "INC_CAT_2_3 = stats.ttest_ind(INC_CAT2_int, INC_CAT3_int, equal_var=False)\n",
    "print('INC_CAT_2_3 = ' + str(INC_CAT_2_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis cannot be rejected for Categories 1&2 and 2&3 - there is no significant difference between the means with respect to interference.\n",
    "\n",
    "The null hypothesis can be rejected for Category 1&3 - there is a significant difference between the means of Category 1 and Category 3 regarding interference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income_CAT vs. Working Memory\n",
    "\n",
    "INC_CAT1_WM = df_cleaned[INC_CAT1].WM_total\n",
    "\n",
    "INC_CAT2_WM = df_cleaned[INC_CAT2].WM_total\n",
    "\n",
    "INC_CAT3_WM = df_cleaned[INC_CAT3].WM_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=3.583679586766644, pvalue=0.028514282531479387)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levene Test\n",
    "\n",
    "stats.levene(INC_CAT1_WM, INC_CAT2_WM, INC_CAT3_WM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variances are equal. As such, ANOVA can be performed on this sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=22.747426873493414, pvalue=1.9234766198514318e-10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assumption #3 - Random Samples\n",
    "\n",
    "Income_1 = np.random.choice(INC_CAT1_WM, size=450)\n",
    "Income_2 = np.random.choice(INC_CAT2_WM, size=450)\n",
    "Income_3 = np.random.choice(INC_CAT3_WM, size=450)\n",
    "\n",
    "# One-Factor ANOVA Test - (Income_CAT vs. Working Memory)\n",
    "\n",
    "stats.f_oneway(Income_1, Income_2, Income_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis can be rejected for the null, which states that at least one inequality exists between the means with respect to working memory. The Tukey Test must now be employed to determine the differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD,FWER=0.05\n",
      "============================================\n",
      "group1 group2 meandiff  lower  upper  reject\n",
      "--------------------------------------------\n",
      " 1.0    2.0    0.879   -0.0527 1.8106 False \n",
      " 1.0    3.0    1.676    0.6902 2.6618  True \n",
      " 2.0    3.0    0.7971  -0.2183 1.8124 False \n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Tukey Test - Income_CAT vs. Working Memory\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "income_tukey = pairwise_tukeyhsd(df_cleaned['WM_total'], df_cleaned['Income_CAT'])\n",
    "print(income_tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis can only be rejected for the comparison between Categories 1&3. This allows for the conclusion that there is a significant difference in mean working memory scores between students from low-income and high-income backgrounds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income_CAT vs. Cognitive Flexibility\n",
    "\n",
    "INC_CAT1_CF = df_cleaned[INC_CAT1].CF_total\n",
    "\n",
    "INC_CAT2_CF = df_cleaned[INC_CAT2].CF_total\n",
    "\n",
    "INC_CAT3_CF = df_cleaned[INC_CAT3].CF_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=4.196902616451289, pvalue=0.015594269095078394)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levene Test\n",
    "\n",
    "stats.levene(INC_CAT1_CF, INC_CAT2_CF, INC_CAT3_CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variances are equal. As such, ANOVA can be performed on this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.9526791384150386, pvalue=0.38596600577096685)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assumption #3 - Random Samples\n",
    "\n",
    "Income_1_CF = np.random.choice(INC_CAT1_CF, size=450)\n",
    "Income_2_CF = np.random.choice(INC_CAT2_CF, size=450)\n",
    "Income_3_CF = np.random.choice(INC_CAT3_CF, size=450)\n",
    "\n",
    "# One-Factor ANOVA Test - (Income_CAT vs. Cognitive Flexibility)\n",
    "\n",
    "stats.f_oneway(Income_1_CF, Income_2_CF, Income_3_CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis cannot be rejected - there is no significant difference between the three group means with respect to cognitive flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age vs. EF Scores**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: There is no significant correlation between age and interference.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between age and interference.\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: There is no significant correlation between age and working memory.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between age and working memory.\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: There is no significant correlation between age and cognitive flexibility.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between age and cognitive flexibility.\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02883339938492646 0.5259900644790236\n",
      "0.054461688551879446 0.2307504350815389\n",
      "-0.14615595040919882 0.0012329849814981715\n"
     ]
    }
   ],
   "source": [
    "# Age vs. Interference\n",
    "\n",
    "age_df = df_cleaned['Actual_age_C']\n",
    "interference = df_cleaned['Interference_score_ALL']\n",
    "\n",
    "r1, p1 = stats.pearsonr(age_df, interference)\n",
    "print(r1, p1)\n",
    "\n",
    "# Age vs. Working Memory\n",
    "\n",
    "working_memory = df_cleaned['WM_total']\n",
    "\n",
    "r2, p2 = stats.pearsonr(age_df, working_memory)\n",
    "print(r2, p2)\n",
    "\n",
    "# Age vs. Cognitive Flexibility\n",
    "\n",
    "cog_flex = df_cleaned['CF_total']\n",
    "\n",
    "r3, p3 = stats.pearsonr(age_df, cog_flex)\n",
    "print(r3, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant negative correlation between age and cognitive flexibility. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight vs. EF Scores**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: There is no significant correlation between weight and interference.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between weight and interference.\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: There is no significant correlation between weight and working memory.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between weight and working memory.\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: There is no significant correlation between weight and cognitive flexibility.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between weight and cognitive flexibility.\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05197570015694715 0.2527696260488067\n",
      "-0.02857035484040373 0.5297736978694546\n",
      "-0.002099492157635246 0.9631787174209964\n"
     ]
    }
   ],
   "source": [
    "# Weight vs. Interference\n",
    "\n",
    "weight_df = df_cleaned['Weight']\n",
    "\n",
    "r1, p1 = stats.pearsonr(weight_df, interference)\n",
    "print(r1, p1)\n",
    "\n",
    "# Weight vs. Working Memory\n",
    "\n",
    "r2, p2 = stats.pearsonr(weight_df, working_memory)\n",
    "print(r2, p2)\n",
    "\n",
    "# Weight vs. Cognitive Flexibility\n",
    "\n",
    "r3, p3 = stats.pearsonr(weight_df, cog_flex)\n",
    "print(r3, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant correlation between weight and executive function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BMI vs. EF Scores**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: There is no significant correlation between BMI and interference.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between BMI and interference.\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: There is no significant correlation between BMI and working memory.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between BMI and working memory.\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: There is no significant correlation between BMI and cognitive flexibility.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between BMI and cognitive flexibility.\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08440781558824864 0.06298005442713729\n",
      "-0.07047840888612275 0.12074496541805409\n",
      "0.00737987624254447 0.8710887915789404\n"
     ]
    }
   ],
   "source": [
    "# BMI vs. Interference\n",
    "\n",
    "BMI_df = df_cleaned['BMI']\n",
    "\n",
    "r1, p1 = stats.pearsonr(BMI_df, interference)\n",
    "print(r1, p1)\n",
    "\n",
    "# BMI vs. Working Memory\n",
    "\n",
    "r2, p2 = stats.pearsonr(BMI_df, working_memory)\n",
    "print(r2, p2)\n",
    "\n",
    "# BMI vs. Cognitive Flexibility\n",
    "\n",
    "r3, p3 = stats.pearsonr(BMI_df, cog_flex)\n",
    "print(r3, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant correlation between BMI and executive function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BMI-for-Age vs. EF Scores**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: There is no significant correlation between BMI-for-Age and interference.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between BMI-for-Age and interference.\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: There is no significant correlation between BMI-for-Age and working memory.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between BMI-for-Age and working memory.\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: There is no significant correlation between BMI-for-Age and cognitive flexibility.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between BMI-for-Age and cognitive flexibility.\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08939871365079644 0.04887259218707688\n",
      "-0.09413478764238381 0.03803249502534941\n",
      "0.03854247348316013 0.39654290240901746\n"
     ]
    }
   ],
   "source": [
    "# BMI-for-Age vs. Interference\n",
    "\n",
    "BMI_for_Age = df_cleaned['BMI_for_age']\n",
    "\n",
    "r1, p1 = stats.pearsonr(BMI_for_Age, interference)\n",
    "print(r1, p1)\n",
    "\n",
    "# BMI-for-Age vs. Working Memory\n",
    "\n",
    "r2, p2 = stats.pearsonr(BMI_for_Age, working_memory)\n",
    "print(r2, p2)\n",
    "\n",
    "# BMI-for-Age vs. Cognitive Flexibility\n",
    "\n",
    "r3, p3 = stats.pearsonr(BMI_for_Age, cog_flex)\n",
    "print(r3, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant negative correlation between BMI-for-age and interference, as well as BMI-for-age and working memory. The correlation between BMI-for-age and cognitive flexibility is insignificant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Physical Fitness Score vs. EF Scores**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: There is no significant correlation between Physical Fitness Score and interference.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between Physical Fitness Score and interference.\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: There is no significant correlation between Physical Fitness Score and working memory.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between Physical Fitness Score and working memory.\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: There is no significant correlation between Physical Fitness Score and cognitive flexibility.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between Physical Fitness Score and cognitive flexibility.\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022730683286735245 0.6171585989708871\n",
      "-0.009479946844289837 0.8348730783764182\n",
      "0.06932231412144733 0.1269750639641181\n"
     ]
    }
   ],
   "source": [
    "# Physical Fitness Score vs. Interference\n",
    "\n",
    "PFS_score = df_cleaned['Physical_fitness_score']\n",
    "\n",
    "r1, p1 = stats.pearsonr(PFS_score, interference)\n",
    "print(r1, p1)\n",
    "\n",
    "# Physical Fitness Score vs. Working Memory\n",
    "\n",
    "r2, p2 = stats.pearsonr(PFS_score, working_memory)\n",
    "print(r2, p2)\n",
    "\n",
    "# Physical Fitness Score vs. Cognitive Flexibility\n",
    "\n",
    "r3, p3 = stats.pearsonr(PFS_score, cog_flex)\n",
    "print(r3, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant correlation between physical fitness scores and executive function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Physical Activity Score vs. EF Scores**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: There is no significant correlation between Physical Activity Score and interference.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between Physical Activity Score and interference.\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: There is no significant correlation between Physical Activity Score and working memory.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between Physical Activity Score and working memory.\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: There is no significant correlation between Physical Activity Score and cognitive flexibility.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between Physical Activity Score and cognitive flexibility.\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.055476183163104084 0.22216703200603152\n",
      "0.04303519334141155 0.34377943944451206\n",
      "0.07125551928683523 0.11669301999911685\n"
     ]
    }
   ],
   "source": [
    "# Physical Activity Score vs. Interference\n",
    "\n",
    "PA_total = df_cleaned['PA_total_score']\n",
    "\n",
    "r1, p1 = stats.pearsonr(PA_total, interference)\n",
    "print(r1, p1)\n",
    "\n",
    "# Physical Activity Score vs. Working Memory\n",
    "\n",
    "r2, p2 = stats.pearsonr(PA_total, working_memory)\n",
    "print(r2, p2)\n",
    "\n",
    "# Physical Activity Score vs. Cognitive Flexibility\n",
    "\n",
    "r3, p3 = stats.pearsonr(PA_total, cog_flex)\n",
    "print(r3, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant correlation between physical activity scores and executive function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sleep Percent vs. EF Scores**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: There is no significant correlation between Sleep Percent and interference.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between Sleep Percent and interference.\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: There is no significant correlation between Sleep Percent and working memory.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between Sleep Percent and working memory.\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: There is no significant correlation between Sleep Percent and cognitive flexibility.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between Sleep Percent and cognitive flexibility.\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11011667044500599 0.01515282853876919\n",
      "0.09185590109230125 0.04296324929047715\n",
      "-0.05706052295913128 0.2092223939482554\n"
     ]
    }
   ],
   "source": [
    "# Sleep Percent vs. Interference\n",
    "\n",
    "sleep_percent = df_cleaned['Sleep_percent']\n",
    "\n",
    "r1, p1 = stats.pearsonr(sleep_percent, interference)\n",
    "print(r1, p1)\n",
    "\n",
    "# Sleep Percent vs. Working Memory\n",
    "\n",
    "r2, p2 = stats.pearsonr(sleep_percent, working_memory)\n",
    "print(r2, p2)\n",
    "\n",
    "# Sleep Percent vs. Cognitive Flexibility\n",
    "\n",
    "r3, p3 = stats.pearsonr(sleep_percent, cog_flex)\n",
    "print(r3, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant positive correlation between sleep percent and interference, as well as sleep percent and working memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Household Size vs. EF Scores**\n",
    "\n",
    "- Interference\n",
    "\n",
    "$H_{o}$: There is no significant correlation between household size and interference.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between household size and interference.\n",
    "\n",
    "- Working Memory\n",
    "\n",
    "$H_{o}$: There is no significant correlation between household size and working memory.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between household size and working memory.\n",
    "\n",
    "- Cognitive Flexibilty\n",
    "\n",
    "$H_{o}$: There is no significant correlation between household size and cognitive flexibility.  \n",
    "\n",
    "$H_{a}$: There is a significant correlation between household size and cognitive flexibility.\n",
    "\n",
    "Î± = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04195222799263026 0.35607039457907286\n",
      "-0.09805274432920359 0.030675513175410597\n",
      "0.08252504843466325 0.06910769439161386\n"
     ]
    }
   ],
   "source": [
    "# Household Size vs. Interference\n",
    "\n",
    "household_size = df_cleaned['Household_size']\n",
    "\n",
    "r1, p1 = stats.pearsonr(household_size, interference)\n",
    "print(r1, p1)\n",
    "\n",
    "# Household Size vs. Working Memory\n",
    "\n",
    "r2, p2 = stats.pearsonr(household_size, working_memory)\n",
    "print(r2, p2)\n",
    "\n",
    "# Household Size vs. Cognitive Flexibility\n",
    "\n",
    "r3, p3 = stats.pearsonr(household_size, cog_flex)\n",
    "print(r3, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant negative correlation between household size and working memory. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
